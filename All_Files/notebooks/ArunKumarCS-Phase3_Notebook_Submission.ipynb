{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "from downcast import reduce\n",
    "import numpy as np\n",
    "\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1932</th>\n",
       "      <th>1933</th>\n",
       "      <th>1934</th>\n",
       "      <th>1935</th>\n",
       "      <th>1936</th>\n",
       "      <th>1937</th>\n",
       "      <th>1938</th>\n",
       "      <th>1939</th>\n",
       "      <th>1940</th>\n",
       "      <th>1941</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_001_CA_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_002_CA_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_003_CA_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_004_CA_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_005_CA_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_3_823_WI_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_3_824_WI_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_3_825_WI_3</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_3_826_WI_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOODS_3_827_WI_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30490 rows × 1941 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    1     2     3     4     5     6     7     8     9     \\\n",
       "id                                                                         \n",
       "HOBBIES_1_001_CA_1     0     0     0     0     0     0     0     0     0   \n",
       "HOBBIES_1_002_CA_1     0     0     0     0     0     0     0     0     0   \n",
       "HOBBIES_1_003_CA_1     0     0     0     0     0     0     0     0     0   \n",
       "HOBBIES_1_004_CA_1     0     0     0     0     0     0     0     0     0   \n",
       "HOBBIES_1_005_CA_1     0     0     0     0     0     0     0     0     0   \n",
       "...                  ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "FOODS_3_823_WI_3       0     0     2     2     0     3     1     4     1   \n",
       "FOODS_3_824_WI_3       0     0     0     0     0     5     0     1     1   \n",
       "FOODS_3_825_WI_3       0     6     0     2     2     4     1     8     5   \n",
       "FOODS_3_826_WI_3       0     0     0     0     0     0     0     0     0   \n",
       "FOODS_3_827_WI_3       0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "                    10    ...  1932  1933  1934  1935  1936  1937  1938  1939  \\\n",
       "id                        ...                                                   \n",
       "HOBBIES_1_001_CA_1     0  ...     2     4     0     0     0     0     3     3   \n",
       "HOBBIES_1_002_CA_1     0  ...     0     1     2     1     1     0     0     0   \n",
       "HOBBIES_1_003_CA_1     0  ...     1     0     2     0     0     0     2     3   \n",
       "HOBBIES_1_004_CA_1     0  ...     1     1     0     4     0     1     3     0   \n",
       "HOBBIES_1_005_CA_1     0  ...     0     0     0     2     1     0     0     2   \n",
       "...                  ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "FOODS_3_823_WI_3       0  ...     1     0     3     0     1     1     0     0   \n",
       "FOODS_3_824_WI_3       3  ...     0     0     0     0     0     0     1     0   \n",
       "FOODS_3_825_WI_3       2  ...     0     0     1     2     0     1     0     1   \n",
       "FOODS_3_826_WI_3       0  ...     1     1     1     4     6     0     1     1   \n",
       "FOODS_3_827_WI_3       0  ...     1     2     0     5     4     0     2     2   \n",
       "\n",
       "                    1940  1941  \n",
       "id                              \n",
       "HOBBIES_1_001_CA_1     0     1  \n",
       "HOBBIES_1_002_CA_1     0     0  \n",
       "HOBBIES_1_003_CA_1     0     1  \n",
       "HOBBIES_1_004_CA_1     2     6  \n",
       "HOBBIES_1_005_CA_1     1     0  \n",
       "...                  ...   ...  \n",
       "FOODS_3_823_WI_3       1     1  \n",
       "FOODS_3_824_WI_3       1     0  \n",
       "FOODS_3_825_WI_3       0     2  \n",
       "FOODS_3_826_WI_3       1     0  \n",
       "FOODS_3_827_WI_3       5     1  \n",
       "\n",
       "[30490 rows x 1941 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_evaluation = pd.read_csv(r'dataset/sales_train_evaluation.csv')\n",
    "sales_evaluation.index = sales_evaluation.id.str.replace('_evaluation', '')\n",
    "sales_evaluation.drop(['id', 'item_id','dept_id','cat_id','store_id','state_id'], axis=1, inplace=True)\n",
    "sales_evaluation.columns = [int(i.replace('d_', '')) for i in sales_evaluation.keys()]\n",
    "sales_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse_from_forecaster(forecaster):\n",
    "    store_metric = {}\n",
    "    for i in tqdm(range(len(sales_evaluation))):\n",
    "        name = sales_evaluation.iloc[i].name\n",
    "        time_series = sales_evaluation.iloc[i]\n",
    "        y_train, y_test = temporal_train_test_split(time_series, test_size=28)\n",
    "        forecaster.fit(y_train)\n",
    "        y_pred = forecaster.predict(fh=[i for i in range(1, 29)])\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=True)\n",
    "        store_metric[name] = rmse\n",
    "    mean_rmse = np.mean(list(store_metric.values()))\n",
    "    return mean_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30490/30490 [02:07<00:00, 239.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Model RMSE:  6.315840540585761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mean_model_rmse = get_rmse_from_forecaster(NaiveForecaster(strategy=\"mean\", sp=7))\n",
    "print('Mean Model RMSE: ', mean_model_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30490/30490 [08:42<00:00, 58.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETS Model RMSE:  5.039344784664702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Auto ETS\n",
    "from sktime.forecasting.ets import AutoETS\n",
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "ETS_model_rmse = get_rmse_from_forecaster(AutoETS(auto=False, sp=7, n_jobs=-1))\n",
    "print('ETS Model RMSE: ', ETS_model_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expontial Smooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30490/30490 [3:10:25<00:00,  2.67it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp Smoothing Model RMSE:  4.873291794654346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sktime.forecasting.exp_smoothing import ExponentialSmoothing\n",
    "\n",
    "exp_smoothing_model_rmse = get_rmse_from_forecaster(ExponentialSmoothing(trend='add', seasonal='add', sp=7))\n",
    "print('Exp Smoothing Model RMSE: ', exp_smoothing_model_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'Model': ['Mean Model', 'ETS Model', 'Exp Smoothing'], 'RMSE': [mean_model_rmse, ETS_model_rmse, exp_smoothing_model_rmse]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mean</td>\n",
       "      <td>6.315841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ETS</td>\n",
       "      <td>5.039345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exp Smoothing</td>\n",
       "      <td>4.873292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model      RMSE\n",
       "0           Mean  6.315841\n",
       "1            ETS  5.039345\n",
       "2  Exp Smoothing  4.873292"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_validation = pd.read_csv(r'dataset/sales_train_validation.csv')\n",
    "sales_evaluation = pd.read_csv(r'dataset/sales_train_evaluation.csv')\n",
    "calendar = pd.read_csv(r'dataset/calendar.csv')\n",
    "prices = pd.read_csv(r'dataset/sell_prices.csv')\n",
    "calendar = calendar.fillna('RegularDay')\n",
    "sales_validation.id = sales_validation.id.str.replace('_validation', '')\n",
    "sales_evaluation.id = sales_evaluation.id.str.replace('_evaluation', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurization for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.34s/it]\n",
      "100%|██████████| 4/4 [00:11<00:00,  2.92s/it]\n",
      "100%|██████████| 10/10 [00:21<00:00,  2.12s/it]\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.35s/it]\n",
      "100%|██████████| 4/4 [00:11<00:00,  2.96s/it]\n",
      "100%|██████████| 10/10 [00:19<00:00,  1.92s/it]\n"
     ]
    }
   ],
   "source": [
    "def featurize_train_data(sales_data, calendar, prices):\n",
    "    melted_sales_validation = pd.melt(sales_data, id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name='d', value_name='sales')\n",
    "    df = pd.merge(melted_sales_validation, calendar, on='d', how='left')\n",
    "    df = pd.merge(df, prices, on=['store_id','item_id','wm_yr_wk'], how='left') \n",
    "    for i in tqdm(list(range(7,30,7))):\n",
    "        df['lag_'+str(i)] = df.groupby(['id'])['sales'].shift(i)\n",
    "        \n",
    "    for i in tqdm(list(range(7,30,7))):\n",
    "        df['rolling_mean_'+str(i)] = df.groupby(['id'])['sales'].shift(i).rolling(i).mean()\n",
    "        df['rolling_std_'+str(i)] = df.groupby(['id'])['sales'].shift(i).rolling(i).std()\n",
    "    df = df.fillna(0)\n",
    "    cols = ['event_name_1','event_type_1','event_name_2','event_type_2','id','item_id','dept_id','cat_id','store_id','state_id']\n",
    "    label_encoders = {}\n",
    "    for i in tqdm(cols):\n",
    "        labelencoder=LabelEncoder()\n",
    "        df[i+'_encoded'] = labelencoder.fit_transform(df[i].astype(str))\n",
    "        label_encoders[i] = labelencoder\n",
    "    df.d = df.d.apply(lambda x: x.split('_')[1]).astype(int)\n",
    "\n",
    "    df = reduce(df)\n",
    "    \n",
    "    x = df.drop(['id','item_id','dept_id','cat_id','store_id','state_id','weekday','date','month','year','event_name_1','event_type_1','event_name_2','event_type_2'], axis=1)\n",
    "    y = df[['d','sales']]\n",
    "    x_train=x.loc[(x['d']>=1115)&(x['d']<=1885)].copy()\n",
    "    x_cv=x.loc[(x['d']>1885)].copy()\n",
    "\n",
    "    y_train=y.loc[(x['d']>=1115)&(y['d']<=1885)].copy()\n",
    "    y_cv=y.loc[(y['d']>1885)].copy()\n",
    "\n",
    "    x_train.drop(['d', 'sales'], axis=1, inplace=True)\n",
    "    x_cv.drop(['d', 'sales'], axis=1, inplace=True)\n",
    "\n",
    "    y_train.drop(['d'], axis=1, inplace=True)\n",
    "    y_cv.drop(['d'], axis=1, inplace=True)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    x_train_std = scaler.fit_transform(x_train)\n",
    "    x_cv_std = scaler.transform(x_cv)\n",
    "\n",
    "    return x_train.columns, scaler, label_encoders, x_train_std, x_cv_std, y_train, y_cv\n",
    "\n",
    "def featurize_test_data(sales_data, calendar, prices, scaler, label_encoders):\n",
    "    melted_sales_validation = pd.melt(sales_data, id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name='d', value_name='sales')\n",
    "    df = pd.merge(melted_sales_validation, calendar, on='d', how='left')\n",
    "    df = pd.merge(df, prices, on=['store_id','item_id','wm_yr_wk'], how='left') \n",
    "    for i in tqdm(list(range(7,30,7))):\n",
    "        df['lag_'+str(i)] = df.groupby(['id'])['sales'].shift(i)\n",
    "        \n",
    "    for i in tqdm(list(range(7,30,7))):\n",
    "        df['rolling_mean_'+str(i)] = df.groupby(['id'])['sales'].shift(i).rolling(i).mean()\n",
    "        df['rolling_std_'+str(i)] = df.groupby(['id'])['sales'].shift(i).rolling(i).std()\n",
    "    df = df.fillna(0)\n",
    "    cols = ['event_name_1','event_type_1','event_name_2','event_type_2','id','item_id','dept_id','cat_id','store_id','state_id']\n",
    "    for i in tqdm(cols):\n",
    "        df[i+'_encoded'] = label_encoders[i].transform(df[i].astype(str))\n",
    "    df.d = df.d.apply(lambda x: x.split('_')[1]).astype(int)\n",
    "\n",
    "    df = reduce(df)\n",
    "    \n",
    "    x = df.drop(['id','item_id','dept_id','cat_id','store_id','state_id','weekday','date','month','year','event_name_1','event_type_1','event_name_2','event_type_2'], axis=1)\n",
    "    y = df[['d','sales']]\n",
    "    x_test = x.loc[(x['d']>=1914)].copy()\n",
    "\n",
    "    y_test = y.loc[(x['d']>=1914)].copy()\n",
    "\n",
    "    x_test.drop(['d', 'sales'], axis=1, inplace=True)\n",
    "\n",
    "    y_test.drop(['d'], axis=1, inplace=True)\n",
    "\n",
    "    x_test_std = scaler.transform(x_test)\n",
    "\n",
    "    return x_test.columns, x_test_std, y_test\n",
    "\n",
    "train_features, scaler, label_encoders, x_train_std, x_cv_std, y_train, y_cv = featurize_train_data(sales_validation, calendar, prices)\n",
    "test_features, x_test_std, y_test = featurize_test_data(sales_evaluation, calendar, prices, scaler, label_encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['wm_yr_wk', 'wday', 'snap_CA', 'snap_TX', 'snap_WI', 'sell_price',\n",
      "       'lag_7', 'lag_14', 'lag_21', 'lag_28', 'rolling_mean_7',\n",
      "       'rolling_std_7', 'rolling_mean_14', 'rolling_std_14', 'rolling_mean_21',\n",
      "       'rolling_std_21', 'rolling_mean_28', 'rolling_std_28',\n",
      "       'event_name_1_encoded', 'event_type_1_encoded', 'event_name_2_encoded',\n",
      "       'event_type_2_encoded', 'id_encoded', 'item_id_encoded',\n",
      "       'dept_id_encoded', 'cat_id_encoded', 'store_id_encoded',\n",
      "       'state_id_encoded'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import TweedieRegressor\n",
    "from lightgbm import LGBMRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [03:16<00:00, 17.83s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l2_reg</th>\n",
       "      <th>train_error</th>\n",
       "      <th>cv_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>2.446404</td>\n",
       "      <td>2.178166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.447000</td>\n",
       "      <td>2.178695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.446991</td>\n",
       "      <td>2.178708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>2.446991</td>\n",
       "      <td>2.178730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>2.446901</td>\n",
       "      <td>2.178846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>2.470704</td>\n",
       "      <td>2.206977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.545640</td>\n",
       "      <td>2.287303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.064857</td>\n",
       "      <td>2.801523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>3.378298</td>\n",
       "      <td>3.123945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>3.378298</td>\n",
       "      <td>3.123945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>3.401201</td>\n",
       "      <td>3.144100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          l2_reg  train_error  cv_error\n",
       "4       0.010000     2.446404  2.178166\n",
       "2       0.000100     2.447000  2.178695\n",
       "0       0.000001     2.446991  2.178708\n",
       "1       0.000010     2.446991  2.178730\n",
       "3       0.001000     2.446901  2.178846\n",
       "5       0.100000     2.470704  2.206977\n",
       "6       1.000000     2.545640  2.287303\n",
       "7      10.000000     3.064857  2.801523\n",
       "8     100.000000     3.378298  3.123945\n",
       "9     100.000000     3.378298  3.123945\n",
       "10  10000.000000     3.401201  3.144100"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tune_sgd_regressor(x_train_std, y_train, x_cv_std, y_cv, l2_reg):\n",
    "    train_scores = []\n",
    "    cv_scores = []\n",
    "    train_error = []\n",
    "    cv_error = []\n",
    "    for l2 in tqdm(l2_reg):\n",
    "        sgd = SGDRegressor(loss='squared_error', penalty='l2', alpha=l2, random_state=0)\n",
    "        sgd.fit(x_train_std, y_train)\n",
    "        train_error_ = mean_squared_error(y_train, np.around(sgd.predict(x_train_std),0), squared=False)\n",
    "        cv_error_ = mean_squared_error(y_cv, np.around(sgd.predict(x_cv_std),0), squared=False)\n",
    "        train_error.append(train_error_)\n",
    "        cv_error.append(cv_error_)\n",
    "    return train_error, cv_error\n",
    "\n",
    "C = [ 0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 100, 10000]\n",
    "train_error, cv_error = tune_sgd_regressor(x_train_std, y_train, x_cv_std, y_cv, l2_reg=C)\n",
    "results_df_linear_regression = pd.DataFrame({'l2_reg':C, 'train_error':train_error, 'cv_error':cv_error})\n",
    "results_df_linear_regression.sort_values(by='cv_error', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [05:03<00:00, 33.72s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_smoothing</th>\n",
       "      <th>train_error</th>\n",
       "      <th>cv_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>6.074611</td>\n",
       "      <td>3.249828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100.0000</td>\n",
       "      <td>3.562972</td>\n",
       "      <td>3.398215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000.0000</td>\n",
       "      <td>3.556178</td>\n",
       "      <td>3.398215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10000.0000</td>\n",
       "      <td>3.556178</td>\n",
       "      <td>3.398215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>10.412797</td>\n",
       "      <td>6.447999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>13.181332</td>\n",
       "      <td>8.780273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>16.997670</td>\n",
       "      <td>12.024037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>22.145534</td>\n",
       "      <td>18.799591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>29.829064</td>\n",
       "      <td>28.107998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var_smoothing  train_error   cv_error\n",
       "5        10.0000     6.074611   3.249828\n",
       "6       100.0000     3.562972   3.398215\n",
       "7      1000.0000     3.556178   3.398215\n",
       "8     10000.0000     3.556178   3.398215\n",
       "4         1.0000    10.412797   6.447999\n",
       "3         0.1000    13.181332   8.780273\n",
       "2         0.0100    16.997670  12.024037\n",
       "1         0.0010    22.145534  18.799591\n",
       "0         0.0001    29.829064  28.107998"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tune_naive_bayes(x_train, y_train, x_cv, y_cv, var_smoothing):\n",
    "    train_error = []\n",
    "    cv_error = []\n",
    "    for var in tqdm(var_smoothing):\n",
    "        nb = GaussianNB(var_smoothing=var)\n",
    "        nb.fit(x_train, y_train)\n",
    "        train_error_ = mean_squared_error(y_train, np.around(nb.predict(x_train),0), squared=False)\n",
    "        cv_error_ = mean_squared_error(y_cv, np.around(nb.predict(x_cv),0), squared=False)\n",
    "        train_error.append(train_error_)\n",
    "        cv_error.append(cv_error_)\n",
    "    return train_error, cv_error\n",
    "var_smoothing = [1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100, 1000, 10000]\n",
    "train_error_nb, cv_error_nb = tune_naive_bayes(x_train_std, y_train, x_cv_std, y_cv, var_smoothing)\n",
    "results_df_nb = pd.DataFrame({'var_smoothing':var_smoothing, 'train_error':train_error_nb, 'cv_error':cv_error_nb})\n",
    "results_df_nb.sort_values(by='cv_error', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [06:33<00:00, 19.68s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>train_error</th>\n",
       "      <th>cv_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2.259054</td>\n",
       "      <td>2.192753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>2.343793</td>\n",
       "      <td>2.195772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>2.381579</td>\n",
       "      <td>2.197011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.361530</td>\n",
       "      <td>2.199432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>2.310163</td>\n",
       "      <td>2.203802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>2.310163</td>\n",
       "      <td>2.203802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>2.463273</td>\n",
       "      <td>2.231982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>2.502923</td>\n",
       "      <td>2.255038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>2.247750</td>\n",
       "      <td>2.271997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>2.230523</td>\n",
       "      <td>2.274726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>2.213961</td>\n",
       "      <td>2.296256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>2.656797</td>\n",
       "      <td>2.406704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>2.656797</td>\n",
       "      <td>2.406704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2.075503</td>\n",
       "      <td>2.454331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2.767814</td>\n",
       "      <td>2.490598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>2.767814</td>\n",
       "      <td>2.490598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2.767814</td>\n",
       "      <td>2.490598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>2.767814</td>\n",
       "      <td>2.490598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>2.007605</td>\n",
       "      <td>2.502255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>2.003085</td>\n",
       "      <td>2.523757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_samples_split  min_samples_leaf  train_error  cv_error\n",
       "16         11                  3                 5     2.259054  2.192753\n",
       "13         10                 24                16     2.343793  2.195772\n",
       "12          9                 19                27     2.381579  2.197011\n",
       "11          8                  4                 2     2.361530  2.199432\n",
       "2          11                 26                14     2.310163  2.203802\n",
       "6          11                  9                14     2.310163  2.203802\n",
       "7           6                 16                23     2.463273  2.231982\n",
       "5           5                 12                11     2.502923  2.255038\n",
       "9          16                 23                25     2.247750  2.271997\n",
       "19         19                 27                28     2.230523  2.274726\n",
       "17         18                  3                23     2.213961  2.296256\n",
       "3           3                 22                 6     2.656797  2.406704\n",
       "0           3                 23                 5     2.656797  2.406704\n",
       "15         16                  7                 7     2.075503  2.454331\n",
       "10          2                  5                 5     2.767814  2.490598\n",
       "8           2                 15                20     2.767814  2.490598\n",
       "14          2                  3                 7     2.767814  2.490598\n",
       "18          2                  7                12     2.767814  2.490598\n",
       "1          19                 21                 5     2.007605  2.502255\n",
       "4          19                 17                 8     2.003085  2.523757"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tune_decision_tree_regressor(x_train, y_train, x_cv, y_cv, max_depths, min_samples_splits, min_samples_leafs, n_iter):\n",
    "    train_error = []\n",
    "    cv_error = []\n",
    "    max_depths_ = []\n",
    "    min_samples_splits_ = []\n",
    "    min_samples_leafs_ = []\n",
    "    for i in tqdm(range(n_iter)):\n",
    "        max_depth = np.random.choice(max_depths, 1, replace=True)[0]\n",
    "        min_samples_split = np.random.choice(min_samples_splits, 1, replace=True)[0]\n",
    "        min_samples_leaf = np.random.choice(min_samples_leafs, 1, replace=True)[0]\n",
    "        dt = DecisionTreeRegressor(max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, random_state=0)\n",
    "        dt.fit(x_train, y_train)\n",
    "        train_error_ = mean_squared_error(y_train, np.around(dt.predict(x_train),0), squared=False)\n",
    "        cv_error_ = mean_squared_error(y_cv, np.around(dt.predict(x_cv),0), squared=False)\n",
    "        max_depths_.append(max_depth)\n",
    "        min_samples_splits_.append(min_samples_split)\n",
    "        min_samples_leafs_.append(min_samples_leaf)\n",
    "        train_error.append(train_error_)\n",
    "        cv_error.append(cv_error_)\n",
    "    return train_error, cv_error, max_depths_, min_samples_splits_, min_samples_leafs_\n",
    "max_depths = list(range(2, 20))\n",
    "min_samples_splits = list(range(2, 30))\n",
    "min_samples_leafs = list(range(2,30))\n",
    "train_error_dt, cv_error_dt, max_depths_, min_samples_splits_, min_samples_leafs_ = tune_decision_tree_regressor(x_train_std, y_train, x_cv_std, y_cv, max_depths, min_samples_splits, min_samples_leafs, n_iter=20)\n",
    "results_dt = pd.DataFrame({'max_depth':max_depths_, 'min_samples_split':min_samples_splits_, 'min_samples_leaf':min_samples_leafs_, 'train_error':train_error_dt, 'cv_error':cv_error_dt})\n",
    "results_dt.sort_values(by='cv_error', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweedie Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:11<00:00, 23.79s/it]\n",
      "100%|██████████| 3/3 [01:06<00:00, 22.00s/it]\n",
      "100%|██████████| 3/3 [00:43<00:00, 14.35s/it]\n",
      "100%|██████████| 3/3 [00:24<00:00,  8.17s/it]\n",
      "100%|██████████| 3/3 [00:13<00:00,  4.63s/it]\n",
      "100%|██████████| 3/3 [00:12<00:00,  4.32s/it]\n",
      "100%|██████████| 3/3 [00:14<00:00,  4.86s/it]\n",
      "100%|██████████| 7/7 [04:06<00:00, 35.20s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>power</th>\n",
       "      <th>train_error</th>\n",
       "      <th>cv_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.1</td>\n",
       "      <td>12.950694</td>\n",
       "      <td>2.719709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.000</td>\n",
       "      <td>1.1</td>\n",
       "      <td>10.606140</td>\n",
       "      <td>2.790567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10.000</td>\n",
       "      <td>1.3</td>\n",
       "      <td>30.479093</td>\n",
       "      <td>2.794545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.000</td>\n",
       "      <td>1.4</td>\n",
       "      <td>51.387356</td>\n",
       "      <td>2.826686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100.000</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.303286</td>\n",
       "      <td>3.056747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100.000</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.325098</td>\n",
       "      <td>3.078801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100.000</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.332904</td>\n",
       "      <td>3.085991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.100</td>\n",
       "      <td>1.1</td>\n",
       "      <td>9.038981</td>\n",
       "      <td>3.114711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1000.000</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.400491</td>\n",
       "      <td>3.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1000.000</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.400119</td>\n",
       "      <td>3.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1000.000</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.400394</td>\n",
       "      <td>3.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.3</td>\n",
       "      <td>69.353221</td>\n",
       "      <td>3.164844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010</td>\n",
       "      <td>1.1</td>\n",
       "      <td>8.060455</td>\n",
       "      <td>3.486667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>1.1</td>\n",
       "      <td>7.993603</td>\n",
       "      <td>3.529907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.4</td>\n",
       "      <td>240.991861</td>\n",
       "      <td>4.232830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.100</td>\n",
       "      <td>1.3</td>\n",
       "      <td>40.793371</td>\n",
       "      <td>4.678297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010</td>\n",
       "      <td>1.3</td>\n",
       "      <td>32.584040</td>\n",
       "      <td>5.801989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>1.3</td>\n",
       "      <td>31.825274</td>\n",
       "      <td>5.934000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.100</td>\n",
       "      <td>1.4</td>\n",
       "      <td>131.197509</td>\n",
       "      <td>7.153914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.010</td>\n",
       "      <td>1.4</td>\n",
       "      <td>98.407607</td>\n",
       "      <td>9.111949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>1.4</td>\n",
       "      <td>95.192894</td>\n",
       "      <td>9.350677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       alpha  power  train_error  cv_error\n",
       "9      1.000    1.1    12.950694  2.719709\n",
       "12    10.000    1.1    10.606140  2.790567\n",
       "13    10.000    1.3    30.479093  2.794545\n",
       "14    10.000    1.4    51.387356  2.826686\n",
       "15   100.000    1.1     3.303286  3.056747\n",
       "16   100.000    1.3     3.325098  3.078801\n",
       "17   100.000    1.4     3.332904  3.085991\n",
       "6      0.100    1.1     9.038981  3.114711\n",
       "20  1000.000    1.4     3.400491  3.144100\n",
       "18  1000.000    1.1     3.400119  3.144100\n",
       "19  1000.000    1.3     3.400394  3.144100\n",
       "10     1.000    1.3    69.353221  3.164844\n",
       "3      0.010    1.1     8.060455  3.486667\n",
       "0      0.001    1.1     7.993603  3.529907\n",
       "11     1.000    1.4   240.991861  4.232830\n",
       "7      0.100    1.3    40.793371  4.678297\n",
       "4      0.010    1.3    32.584040  5.801989\n",
       "1      0.001    1.3    31.825274  5.934000\n",
       "8      0.100    1.4   131.197509  7.153914\n",
       "5      0.010    1.4    98.407607  9.111949\n",
       "2      0.001    1.4    95.192894  9.350677"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def tune_tweedie(x_train, y_train, x_cv, y_cv, alpha, power):\n",
    "    train_error = []\n",
    "    cv_error = []\n",
    "    alpha_ = []\n",
    "    power_ = []\n",
    "    for var in tqdm(alpha):\n",
    "        for p in tqdm(power):\n",
    "            nb = TweedieRegressor(alpha=var, power=p)\n",
    "            nb.fit(x_train, y_train)\n",
    "            train_error_ = mean_squared_error(y_train, np.around(nb.predict(x_train),0), squared=False)\n",
    "            cv_error_ = mean_squared_error(y_cv, np.around(nb.predict(x_cv),0), squared=False)\n",
    "            train_error.append(train_error_)\n",
    "            cv_error.append(cv_error_)\n",
    "            alpha_.append(var)\n",
    "            power_.append(p)\n",
    "    return train_error, cv_error, alpha_, power_\n",
    "\n",
    "alpha = [1e-3, 1e-2, 1e-1, 1, 10, 100, 1000]\n",
    "power = [1.1, 1.3, 1.4]\n",
    "train_error_tweedie, cv_error_tweedie, alpha_, power_ = tune_tweedie(x_train_std, y_train, x_cv_std, y_cv, alpha, power)\n",
    "results_df_tweedie = pd.DataFrame({'alpha':alpha_, 'power':power_, 'train_error':train_error_tweedie, 'cv_error':cv_error_tweedie})\n",
    "results_df_tweedie.sort_values(by='cv_error', ascending=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [18:52<00:00, 113.22s/it]\n"
     ]
    }
   ],
   "source": [
    "def tune_lgbm(x_train, y_train, x_cv, y_cv, n_estimators, max_depths, num_leaves, learning_rates, reg_lambdas, n_iter):\n",
    "    train_error = []\n",
    "    cv_error = []\n",
    "    n_estimators_ = []\n",
    "    max_depths_ = []\n",
    "    learning_rates_ = []\n",
    "    num_leaves_ = []\n",
    "    reg_lambdas_ = []\n",
    "    for i in tqdm(range(n_iter)):\n",
    "        n_estimator = np.random.choice(n_estimators, 1, replace=True)[0]\n",
    "        max_depth = np.random.choice(max_depths, 1, replace=True)[0]\n",
    "        learning_rate = np.random.choice(learning_rates, 1, replace=True)[0]\n",
    "        num_leaf = np.random.choice(num_leaves, 1, replace=True)[0]\n",
    "        reg_lambda = np.random.choice(reg_lambdas, 1, replace=True)[0]\n",
    "        lgbm = LGBMRegressor(objective='tweedie', \n",
    "                            tweedie_variance_power=1.1,\n",
    "                            n_estimators=n_estimator, \n",
    "                            num_leaves=num_leaf,\n",
    "                            max_depth=max_depth, \n",
    "                            learning_rate=learning_rate, \n",
    "                            reg_lambda = reg_lambda,\n",
    "                            n_jobs=-1,\n",
    "                            random_state=0)\n",
    "        lgbm.fit(x_train, y_train)\n",
    "        train_error_ = mean_squared_error(y_train, np.around(lgbm.predict(x_train),0), squared=False)\n",
    "        cv_error_ = mean_squared_error(y_cv, np.around(lgbm.predict(x_cv),0), squared=False)\n",
    "\n",
    "        n_estimators_.append(n_estimator)\n",
    "        max_depths_.append(max_depth)\n",
    "        learning_rates_.append(learning_rate)\n",
    "        num_leaves_.append(num_leaf)\n",
    "        reg_lambdas_.append(reg_lambda)\n",
    "        train_error.append(train_error_)\n",
    "        cv_error.append(cv_error_)\n",
    "    return train_error, cv_error, n_estimators_, max_depths_, learning_rates_, num_leaves_, reg_lambdas_\n",
    "\n",
    "# Tune lgbm\n",
    "n_estimators = [100, 1000]\n",
    "max_depths = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "num_leaves = [100000]\n",
    "learning_rates = [0.01, 0.1, 0.3]\n",
    "reg_lambdas = [0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "train_error_lgbm, cv_error_lgbm, n_estimators_, max_depths_, learning_rates_, num_leaves_, reg_lambdas_ = tune_lgbm(x_train_std, y_train, x_cv_std, y_cv, n_estimators, max_depths, num_leaves, learning_rates, reg_lambdas, n_iter = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>train_error</th>\n",
       "      <th>cv_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.932674</td>\n",
       "      <td>2.096811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.329517</td>\n",
       "      <td>2.132988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.360733</td>\n",
       "      <td>2.135046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.707952</td>\n",
       "      <td>2.135951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>0.30</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.062610</td>\n",
       "      <td>2.285918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.30</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.498984</td>\n",
       "      <td>2.287496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.299552</td>\n",
       "      <td>2.323150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>11</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.521621</td>\n",
       "      <td>2.380228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.642418</td>\n",
       "      <td>2.398913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.30</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.737117</td>\n",
       "      <td>2.470182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  max_depth  learning_rate  num_leaves  reg_lambda  \\\n",
       "7          1000         10           0.01      100000         0.3   \n",
       "0          1000          5           0.01      100000         0.3   \n",
       "3           100          3           0.30      100000         0.5   \n",
       "1           100         12           0.10      100000         0.5   \n",
       "4           100          7           0.30      100000         0.9   \n",
       "9          1000          7           0.30      100000         0.3   \n",
       "6          1000          8           0.30      100000         0.5   \n",
       "2           100         11           0.01      100000         0.3   \n",
       "5           100          7           0.01      100000         0.5   \n",
       "8          1000         11           0.30      100000         0.9   \n",
       "\n",
       "   train_error  cv_error  \n",
       "7     1.932674  2.096811  \n",
       "0     2.329517  2.132988  \n",
       "3     2.360733  2.135046  \n",
       "1     1.707952  2.135951  \n",
       "4     2.062610  2.285918  \n",
       "9     1.498984  2.287496  \n",
       "6     1.299552  2.323150  \n",
       "2     2.521621  2.380228  \n",
       "5     2.642418  2.398913  \n",
       "8     0.737117  2.470182  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_lgbm = pd.DataFrame({'n_estimators':n_estimators_, 'max_depth':max_depths_, 'learning_rate':learning_rates_, 'num_leaves':num_leaves_, 'reg_lambda':reg_lambdas_, 'train_error':train_error_lgbm, 'cv_error':cv_error_lgbm})\n",
    "results_lgbm.sort_values(by='cv_error', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBM regressor</td>\n",
       "      <td>2.096811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linear regression (L2 regularization)</td>\n",
       "      <td>2.178166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTree regressor</td>\n",
       "      <td>2.192753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tweedie regressor</td>\n",
       "      <td>2.719709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>3.249828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exponential Smoothing</td>\n",
       "      <td>4.873292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ETS Model</td>\n",
       "      <td>5.039345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple mean model</td>\n",
       "      <td>6.315841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Models      RMSE\n",
       "7                     LightGBM regressor  2.096811\n",
       "3  linear regression (L2 regularization)  2.178166\n",
       "5                 DecisionTree regressor  2.192753\n",
       "6                      Tweedie regressor  2.719709\n",
       "4                   Gaussian Naive Bayes  3.249828\n",
       "2                  Exponential Smoothing  4.873292\n",
       "1                              ETS Model  5.039345\n",
       "0                      Simple mean model  6.315841"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models = pd.DataFrame({\n",
    "    'Models':['Simple mean model', 'ETS Model', 'Exponential Smoothing', \n",
    "                    'linear regression (L2 regularization)', 'Gaussian Naive Bayes', \n",
    "                    'DecisionTree regressor', 'Tweedie regressor', 'LightGBM regressor'],\n",
    "    'RMSE':[6.315841,5.039345, 4.873292, 2.178166, 3.249828, 2.192753,2.719709, 2.096811]})\n",
    "best_models.sort_values(by='RMSE', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 2.429733028188093\n",
      "CV error: 2.1574791043294232\n",
      "Test error: 2.2686696080810513\n"
     ]
    }
   ],
   "source": [
    "best_linear_reg = SGDRegressor(alpha=0.01, penalty='l2', random_state=0)\n",
    "best_linear_reg.fit(x_train_std, y_train)\n",
    "print('Train error:', mean_squared_error(y_train, best_linear_reg.predict(x_train_std), squared=False))\n",
    "print('CV error:', mean_squared_error(y_cv, best_linear_reg.predict(x_cv_std), squared=False))\n",
    "print('Test error:', mean_squared_error(y_test, best_linear_reg.predict(x_test_std), squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 2.241267230273972\n",
      "CV error: 2.1724272380972334\n",
      "Test error: 2.3791142037350785\n"
     ]
    }
   ],
   "source": [
    "best_decision_tree = DecisionTreeRegressor(max_depth=11, min_samples_split=3, min_samples_leaf=5, random_state=0)\n",
    "best_decision_tree.fit(x_train_std, y_train)\n",
    "print('Train error:', mean_squared_error(y_train, best_decision_tree.predict(x_train_std), squared=False))\n",
    "print('CV error:', mean_squared_error(y_cv, best_decision_tree.predict(x_cv_std), squared=False))\n",
    "print('Test error:', mean_squared_error(y_test, best_decision_tree.predict(x_test_std), squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 1.9126752394933386\n",
      "CV error: 2.0743967552440843\n",
      "Test error: 2.20561306979029\n"
     ]
    }
   ],
   "source": [
    "best_lightgbm = LGBMRegressor(objective='tweedie', tweedie_variance_power=1.1, n_estimators=1000, num_leaves=100000, max_depth=10, learning_rate=0.01, reg_lambda = 0.3, n_jobs=-1, random_state=0) \n",
    "best_lightgbm.fit(x_train_std, y_train)\n",
    "print('Train error:', mean_squared_error(y_train, best_lightgbm.predict(x_train_std), squared=False))\n",
    "print('CV error:', mean_squared_error(y_cv, best_lightgbm.predict(x_cv_std), squared=False))\n",
    "print('Test error:', mean_squared_error(y_test, best_lightgbm.predict(x_test_std), squared=False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>CV RMSE</th>\n",
       "      <th>Test RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM regressor</td>\n",
       "      <td>1.912675</td>\n",
       "      <td>2.074397</td>\n",
       "      <td>2.205613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression with L2 Regularization</td>\n",
       "      <td>2.429733</td>\n",
       "      <td>2.157479</td>\n",
       "      <td>2.268670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTree regressor</td>\n",
       "      <td>2.241267</td>\n",
       "      <td>2.172427</td>\n",
       "      <td>2.379114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Models  Train RMSE   CV RMSE  Test RMSE\n",
       "2                        LightGBM regressor    1.912675  2.074397   2.205613\n",
       "0  Linear Regression with L2 Regularization    2.429733  2.157479   2.268670\n",
       "1                    DecisionTree regressor    2.241267  2.172427   2.379114"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas table of best models\n",
    "best_models = pd.DataFrame({\n",
    "    'Models':['Linear Regression with L2 Regularization', 'DecisionTree regressor', 'LightGBM regressor'],\n",
    "    'Train RMSE':[2.429733028188093,2.241267230273972, 1.9126752394933386],\n",
    "    'CV RMSE':[2.1574791043294232, 2.1724272380972334, 2.0743967552440843],\n",
    "    'Test RMSE':[2.2686696080810513, 2.3791142037350785, 2.20561306979029]})\n",
    "best_models.sort_values(by='Test RMSE', ascending=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9baaabb7af3f92ae09d746be89d264ca11beda4dade21bcf0e4e74ca662ee82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
